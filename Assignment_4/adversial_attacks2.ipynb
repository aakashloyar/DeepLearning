{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms, datasets \n",
    "import torch.nn as nn\n",
    "import torchattacks\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformation for images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  # Resize to match the model input\n",
    "    transforms.ToTensor()        # Convert to Tensor\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "dataset = datasets.ImageFolder(root=\"data//tiny-imagenet-200/train\", transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=30, shuffle=True)\n",
    "\n",
    "#Get a batch of images and labels\n",
    "images, labels = next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get class labels\n",
    "classes = dataset.classes\n",
    "model = models.vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference between original and adversarial images (L2 norm): 0.0\n"
     ]
    }
   ],
   "source": [
    "#Load a pre-trained VGG16 model.\n",
    "model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
    "num_classes = len(classes)\n",
    "\n",
    "# Modify the classifier to suit the new task\n",
    "model.classifier[5] = nn.Dropout(p=0.5)\n",
    "model.classifier[6] = nn.Linear(in_features=4096, out_features=num_classes, bias=True)\n",
    "\n",
    "#Update the classifier for the no. of classes in ur dataset\n",
    "# model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
    "model.eval()\n",
    "# attack = torchattacks.FGSM(model, eps=58/255)\n",
    "attack = torchattacks.DeepFool(model, steps=50, overshoot=0.02)\n",
    "adv_images = attack(images, labels)\n",
    "diff = torch.norm(adv_images - images, p=2)\n",
    "print(\"Difference between original and adversarial images (L2 norm):\", diff.item())\n",
    "adv_outputs = model(adv_images)\n",
    "_, preds_perturbed = torch.max(adv_outputs, 1)\n",
    "_, original_preds = torch.max(model(images), 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n04275548:n02927161=> Yes label is misclassified\n",
      "n02129165:n02666196=> Yes label is misclassified\n",
      "n09246464:n02666196=> Yes label is misclassified\n",
      "n02226429:n04562935=> Yes label is misclassified\n",
      "n07747607:n07711569=> Yes label is misclassified\n",
      "n01629819:n02927161=> Yes label is misclassified\n",
      "n02769748:n07711569=> Yes label is misclassified\n",
      "n02769748:n02927161=> Yes label is misclassified\n",
      "n04179913:n03937543=> Yes label is misclassified\n",
      "n01855672:n07875152=> Yes label is misclassified\n",
      "n03838899:n02699494=> Yes label is misclassified\n",
      "n04149813:n04562935=> Yes label is misclassified\n",
      "n02666196:n09256479=> Yes label is misclassified\n",
      "n02917067:n09256479=> Yes label is misclassified\n",
      "n04562935:n03014705=> Yes label is misclassified\n",
      "n02814860:n02481823=> Yes label is misclassified\n",
      "n03355925:n02124075=> Yes label is misclassified\n",
      "n03400231:n09256479=> Yes label is misclassified\n",
      "n03085013:n09256479=> Yes label is misclassified\n",
      "n04532670:n01629819=> Yes label is misclassified\n",
      "n02843684:n02699494=> Yes label is misclassified\n",
      "n02125311:n04254777=> Yes label is misclassified\n",
      "n04265275:n02666196=> Yes label is misclassified\n",
      "n02843684:n03584254=> Yes label is misclassified\n",
      "n07579787:n04532670=> Yes label is misclassified\n",
      "n04596742:n02666196=> Yes label is misclassified\n",
      "n04265275:n09256479=> Yes label is misclassified\n",
      "n02699494:n07753592=> Yes label is misclassified\n",
      "n04562935:n04366367=> Yes label is misclassified\n",
      "n01629819:n03014705=> Yes label is misclassified\n"
     ]
    }
   ],
   "source": [
    "for i in range(images.size(0)): \n",
    "    original_label = classes[original_preds[i].item()]\n",
    "    adversarial_label = classes[preds_perturbed[i]]\n",
    "    \n",
    "    if original_label == adversarial_label:\n",
    "        print(f\"{original_label}: Label Not misclassified\")\n",
    "    else:\n",
    "        print(f\"{original_label}:{adversarial_label}=> Yes label is misclassified\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
