{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aakash\n",
    "\n",
    "EP21BTECH11001\n",
    "\n",
    "HW-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1 Numpy Implementation\n",
    "In this assignment you will implement each of the components of a Convolutional Neural Network (CNN)\n",
    "\n",
    "from scratch (i.e., without using built-in functions for convolution, pooling, non-linearity, padding, strid-\n",
    "ing). Your implementation must accept an image input and generate an output vector. Use random weights\n",
    "\n",
    "for filter kernels and fully connected layers. Specifically, implement the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Convolution function: It accepts as input an image, a filter kernel, stride, padding and the non-linear\n",
    "function. The function must correlate (convolve) the input image (after padding if specified) with\n",
    "the kernel (at the specified stride size) and generate an output activation after applying the specified\n",
    "non-linearity. Verify with the standard options for the non-linear activation functions - sigmoid,\n",
    "tanh, ReLU, Parametric ReLU (PReLU). Display the input image, the filter kernel and the output\n",
    "activation map. Ensure that your function can accept multi-channel input and a corresponding kernel\n",
    "volume. (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def tanhx(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "def prelu(x,alpha=0.1):\n",
    "    return np.where(x>0,x,alpha*x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avgPooling(input,output,kernel_h,kernel_w,stride):\n",
    "    input_h,input_w,channels=input.shape\n",
    "    output_h,output_w,channels=output.shape\n",
    "    for c in range(channels):\n",
    "        for h in range(output_h):\n",
    "            for w in range(output_w):\n",
    "                sum=0.0\n",
    "                for i in range(kernel_h):\n",
    "                    for j in range(kernel_w):\n",
    "                        sum+=input[(h*stride)+i][(w*stride)+j][c]\n",
    "                sum/=(kernel_h*kernel_w)\n",
    "                output[h*stride][w*stride]=sum\n",
    "    return output\n",
    "\n",
    "\n",
    "\n",
    "def maxPooling(input,output,kernel_h,kernel_w,stride):\n",
    "    input_h,input_w,channels=input.shape\n",
    "    output_h,output_w,channels=output.shape\n",
    "    for c in range(channels):\n",
    "        for h in range(output_h):\n",
    "            for w in range(output_w):\n",
    "                max = float('-inf')\n",
    "                for i in range(kernel_h):\n",
    "                    for j in range(kernel_w):\n",
    "                        res=max(input[(h*stride)+i][(w*stride)+j][c],res)\n",
    "                output[h*stride][w*stride]=res\n",
    "    return output\n",
    "\n",
    "\n",
    "def minPooling(input,output,kernel_h,kernel_w,stride):\n",
    "    input_h,input_w,channels=input.shape\n",
    "    output_h,output_w,channels=output.shape\n",
    "    for c in range(channels):\n",
    "        for h in range(output_h):\n",
    "            for w in range(output_w):\n",
    "                res = float('inf')\n",
    "                for i in range(kernel_h):\n",
    "                    for j in range(kernel_w):\n",
    "                        res=min(input[(h*stride)+i][(w*stride)+j][c],res)\n",
    "                output[h*stride][w*stride]=res\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. first of all implement convolution function\n",
    "# input: image filter/kernel/stride/padding/non-linear fctn\n",
    "# conventions: image_h/image_w/channels/kernel_h/kernel_w/kernel_channels\n",
    "# checkconditns: channels==kernel_channels/\n",
    "\n",
    "def Convolution(image,kernel,stride,padding,activation):\n",
    "\n",
    "    #add padding first to image with filling 0 to padding cells\n",
    "    image = np.pad(image, ((padding, padding), (padding, padding), (0, 0)), mode='constant')\n",
    "\n",
    "    # size of imputs\n",
    "    image_h,image_w,channels=image.shape\n",
    "    kernel_h,kernel_w,kernel_channels=kernel.shape\n",
    "\n",
    "    # necessary condition check\n",
    "    if kernel_channels!=channels:\n",
    "        raise ValueError(\"Kernel and image must have same no of channels\")\n",
    "\n",
    "    #now getting the output size   \n",
    "    # dimension of output matrix -> (n-l+2p)/s+1 \n",
    "    output_h=int(((image_h-kernel_h)/stride)+1)\n",
    "    output_w=int(((image_w-kernel_w)/stride)+1)\n",
    "    output=np.zeros((output_h,output_w,channels))\n",
    "    for c in range(channels):\n",
    "        for h in range(output_h):\n",
    "            for w in range(output_w):\n",
    "                curr=0\n",
    "                for i in range(kernel_h):\n",
    "                    for j in range(kernel_w):\n",
    "                        curr+=kernel[i][j][c]*image[(h*stride)+i][(w*stride)+j][c]\n",
    "                output[h*stride][w*stride][c]=curr\n",
    "\n",
    "    if(activation=='sig'):\n",
    "        output=sigmoid(output)\n",
    "    if(activation=='tanhx'):\n",
    "        output=tanhx(output)\n",
    "    if(activation=='relu'):\n",
    "        output=relu(output)\n",
    "    if(activation=='prelu'):\n",
    "        output=prelu(output)\n",
    "    print(image)\n",
    "    print(kernel)\n",
    "    print(output)\n",
    "    return output    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Pooling function: It accepts as input the activation map output from the convolution function, a\n",
    "pooling function, and stride. The function must output the appropriately pooled activation map.\n",
    "Display the input activation map and the pooled output. (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. now will will implement pooling function\n",
    "# input-> inputmap/pooling function/stride/dimensionofkernel\n",
    "def Pooling(inputmap,pooling_fctn,stride,kernel_h,kernel_w):\n",
    "\n",
    "    # getting the inputmap dimensions\n",
    "    inputmap_h,inputmap_w,channels=inputmap.shape\n",
    "\n",
    "    # getting the outputmap dimensions\n",
    "    outputmap_h=int(((inputmap_h-kernel_h)/stride)+1)\n",
    "    outputmap_w=int(((inputmap_w-kernel_w)/stride)+1)\n",
    "    outputmap=np.zeros((outputmap_h,outputmap_w,channels))\n",
    "    if(pooling_fctn=='max'):\n",
    "        outputmap=maxPooling(inputmap,outputmap,kernel_h,kernel_w,stride)\n",
    "    \n",
    "    print(inputmap)\n",
    "    print(outputmap)\n",
    "    return outputmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Convolution layer function: It accepts as input a volume (image or activation maps), filter kernels,\n",
    "stride, padding and the non-linear function. The function must convolve the input volume (after\n",
    "padding if specified) with each of the kernels (at the specified stride size) and generates an output\n",
    "activation volume after applying the specified non-linearity. Display the input image or activation\n",
    "maps, the filter kernels and the output activation maps. Verify that the output of this function does\n",
    "indeed have the expected size (W × H × C) as discussed in class. (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Convolution layer function\n",
    "def ConvolutionLayer(input_volume, kernels, stride, padding, activation):\n",
    "    # Add padding to the input volume\n",
    "    input_volume = np.pad(input_volume, ((padding, padding), (padding, padding), (0, 0)), mode='constant')\n",
    "\n",
    "    # Get dimensions of the input and kernel\n",
    "    input_h, input_w, input_channels = input_volume.shape\n",
    "    kernel_h, kernel_w, kernel_channels, num_kernels = kernels.shape\n",
    "\n",
    "    # Check if kernel channels match input channels\n",
    "    if kernel_channels != input_channels:\n",
    "        raise ValueError(\"Kernel and input volume must have the same number of channels\")\n",
    "\n",
    "    # Calculate output dimensions\n",
    "    output_h = int((input_h - kernel_h) / stride + 1)\n",
    "    output_w = int((input_w - kernel_w) / stride + 1)\n",
    "    output_volume = np.zeros((output_h, output_w,kernel_channels, num_kernels))\n",
    "\n",
    "    # Convolve each kernel with the input volume and store in the output volume\n",
    "    for k in range(num_kernels):\n",
    "        output_volume[:, :,:, k] = Convolution(input_volume, kernels[:, :, :, k], stride)\n",
    "\n",
    "    # Apply activation function\n",
    "    if activation == 'sig':\n",
    "        output_volume = sigmoid(output_volume)\n",
    "    elif activation == 'tanhx':\n",
    "        output_volume = tanhx(output_volume)\n",
    "    elif activation == 'relu':\n",
    "        output_volume = relu(output_volume)\n",
    "    elif activation == 'prelu':\n",
    "        output_volume = prelu(output_volume)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported activation function\")\n",
    "\n",
    "    # Display input volume, kernels, and output volume\n",
    "    print(\"Input Volume:\\n\", input_volume)\n",
    "    print(\"Kernels:\\n\", kernels)\n",
    "    print(\"Output Activation Volume:\\n\", output_volume)\n",
    "    \n",
    "    return output_volume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Pooling layer function: It accepts as input the activation map volume, the pooling function, stride,\n",
    "and generates a pooled output volume. Display the input and output volumes. (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. now will will implement pooling function\n",
    "# input-> inputmap/pooling function/stride/dimensionofkernel\n",
    "def Pooling(inputmap,pooling_fctn,stride,kernel_h,kernel_w):\n",
    "\n",
    "    # getting the inputmap dimensions\n",
    "    inputmap_h,inputmap_w,channels,inputmap_num=inputmap.shape\n",
    "\n",
    "    # getting the outputmap dimensions\n",
    "    outputmap_h=int(((inputmap_h-kernel_h)/stride)+1)\n",
    "    outputmap_w=int(((inputmap_w-kernel_w)/stride)+1)\n",
    "    outputmap=np.zeros((outputmap_h,outputmap_w,channels,inputmap_num))\n",
    "    if(pooling_fctn=='max'):\n",
    "        for k in range(inputmap_num):\n",
    "            outputmap[:,:,:,k]=maxPooling(inputmap,outputmap,kernel_h,kernel_w,stride)\n",
    "    elif(pooling_fctn=='min'):\n",
    "        for k in range(inputmap_num):\n",
    "            outputmap[:,:,:,k]=minPooling(inputmap,outputmap,kernel_h,kernel_w,stride)\n",
    "    elif(pooling_fctn=='avg'):\n",
    "        for k in range(inputmap_num):\n",
    "            outputmap[:,:,:,k]=avgPooling(inputmap,outputmap,kernel_h,kernel_w,stride)\n",
    "    \n",
    "    print(inputmap)\n",
    "    print(outputmap)\n",
    "    return outputmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Flattening (unraveling) function: It accepts as input the activation map volume output by the pool-\n",
    "ing layer and generates a vector of a specified size. It is important to note that this function has a\n",
    "weight matrix associated with it whose size is chosen such that the input and desired output sizes are\n",
    "matched. (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 flatten function\n",
    "def flatten(input_volume):\n",
    "    return input_volume.flatten()\n",
    "\n",
    "def flatten_with_weights(input_volume, weight_matrix):\n",
    "    # Flatten the input volume\n",
    "    flattened_vector = flatten(input_volume)\n",
    "\n",
    "    if flattened_vector.size != weight_matrix.shape[1]:\n",
    "        raise ValueError(\"Flattened input size must match weight matrix input size.\")\n",
    "\n",
    "    output_vector = np.dot(weight_matrix, flattened_vector)\n",
    "    return output_vector\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
